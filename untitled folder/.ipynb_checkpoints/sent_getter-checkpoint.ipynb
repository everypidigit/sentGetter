{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b74908-08e0-4c7d-838b-4b5acb7fad7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Doing the same thing, but with a PDF File. \n",
    "Does not work as well since PDF readers are not perfect and capture a lot of redundant information, as well as do not distinguish between different types of text. \n",
    "Some words are also weirdly cut. Though it works pretty fine even in this very basic form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70850b37-b6da-410d-9258-bd8c821b40fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /Users/daniyar/opt/miniconda3/envs/compchem/lib/python3.8/site-packages (2.10.5)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /Users/daniyar/opt/miniconda3/envs/compchem/lib/python3.8/site-packages (from PyPDF2) (4.3.0)\n",
      "Requirement already satisfied: pandas in /Users/daniyar/opt/miniconda3/envs/compchem/lib/python3.8/site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/daniyar/opt/miniconda3/envs/compchem/lib/python3.8/site-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/daniyar/opt/miniconda3/envs/compchem/lib/python3.8/site-packages (from pandas) (2022.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/daniyar/opt/miniconda3/envs/compchem/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/daniyar/opt/miniconda3/envs/compchem/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: nltk in /Users/daniyar/opt/miniconda3/envs/compchem/lib/python3.8/site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/daniyar/opt/miniconda3/envs/compchem/lib/python3.8/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in /Users/daniyar/opt/miniconda3/envs/compchem/lib/python3.8/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /Users/daniyar/opt/miniconda3/envs/compchem/lib/python3.8/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in /Users/daniyar/opt/miniconda3/envs/compchem/lib/python3.8/site-packages (from nltk) (4.64.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install PyPDF2\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5be5584-affd-4f3d-a5ad-eeedf0850038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from timeit import timeit\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb8dc7d9-2d7a-4539-8401-bb84bdc1e132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/daniyar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/daniyar/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222d19c8-61f5-48fa-bace-9df11973d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pdf file object\n",
    "chem_file = open('chem.pdf', 'rb')\n",
    "chem_reader = PyPDF2.PdfFileReader(chem_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6be8edc-c376-41f2-bb15-25cfc59bf0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pass_sent_list = []\n",
    "token_list = []\n",
    "nltk_verbs = 0\n",
    "counts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15718d19-b257-4de1-9911-28acb025b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['is','are','was','were', 'be', 'have','has','would','will','had']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fb000d7-5a73-4fb2-b5e9-090792c3a2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentence_getter(file, starting_page, last_page):\n",
    "    pass_sent_list = []\n",
    "    token_list = []\n",
    "    nltk_verbs = 0\n",
    "    counts = []\n",
    "    for p in range(starting_page, last_page):\n",
    "        page = (file.getPage(p))\n",
    "        pages_text = page.extractText()\n",
    "        \n",
    "        pages_text_tokenized = nltk.word_tokenize(pages_text)\n",
    "        pages_text_tokenized_tagged = nltk.pos_tag(pages_text_tokenized)\n",
    "        \n",
    "        pages_text_split = (pages_text.split())\n",
    "        \n",
    "        token_list.append(pages_text_tokenized_tagged)\n",
    "        \n",
    "        # pages_text_split = (file.getPage(p).extractText().split())  #the same thing as the three lines above, but written in one line. I just prefer the cleaner look.\n",
    "\n",
    "        for i in range(0, len(pages_text_split)):\n",
    "            if pages_text_split[i] in target:\n",
    "                if i+1 == None:\n",
    "                    pass_sent_list.extend([[pages_text_split[i-2], pages_text_split[i-1], pages_text_split[i]]])\n",
    "                elif i-1 == None:\n",
    "                    pass_sent_list.extend([[pages_text_split[i], pages_text_split[i+1], pages_text_split[i+2]]])\n",
    "                else: \n",
    "                    pass_sent_list.extend([[pages_text_split[i-2], pages_text_split[i-1], pages_text_split[i], pages_text_split[i+1], pages_text_split[i+2]]])\n",
    "\n",
    "    for l in range(len(token_list)):\n",
    "        counts.append(Counter(tag for word,tag in token_list[l]))\n",
    "\n",
    "    for c in range(len(counts)):\n",
    "        nltk_verbs = nltk_verbs + counts[c]['VBZ']\n",
    "        nltk_verbs = nltk_verbs + counts[c]['VBN']\n",
    "        nltk_verbs = nltk_verbs + counts[c]['VB']\n",
    "        nltk_verbs = nltk_verbs + counts[c]['VBD']\n",
    "        nltk_verbs = nltk_verbs + counts[c]['VBG']\n",
    "        nltk_verbs = nltk_verbs + counts[c]['VBP'] \n",
    "    \n",
    "    passDF = pd.DataFrame(pass_sent_list)\n",
    "    passDF.to_csv('sent.csv', index=False)\n",
    "    # return len(counts)\n",
    "    return print('VB[X] verbs length = {} \\nPassive Voice Sentences length = {}\\nratio of (passive/overall) = {}%\\nPlease, remember that this ratio is quite likely to be incorrect. You can rewrite everything if you want to :)\\nYour passive sentences list has been saved as a .csv file in the directory in which this program is in as \"sent.csv\"'.format(nltk_verbs, len(pass_sent_list), (len(pass_sent_list)/nltk_verbs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcee5533-9400-4022-94b3-4e7e3e47abbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB[X] verbs length = 115 \n",
      "Passive Voice Sentences length = 14\n",
      "ratio of (passive/overall) = 0.12173913043478261%\n",
      "Please, remember that this ratio is quite likely to be incorrect. You can rewrite everything if you want to :)\n",
      "Your passive sentences list has been saved as a .csv file in the directory in which this program is in as \"sent.csv\"\n"
     ]
    }
   ],
   "source": [
    "# parameters are: (name_of_the_reader, first_page_you_want_to_check, last_page_you_want_to_check)\n",
    "sentence_getter(chem_reader, 0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a93ccd3-20ff-4317-9ee7-b5c1df377e90",
   "metadata": {},
   "source": [
    "### All of the other tags are in this post. If you want to add anything to be counted, you can do it yourself. I can always help with this, but I am 100% sure that you can easily do it yourself)\n",
    "https://stackoverflow.com/questions/15388831/what-are-all-possible-pos-tags-of-nltk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
